{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import key BCAI ART modules related to:\n",
    "1. a dataset\n",
    "2. a model\n",
    "3. a training environment\n",
    "4. a training and test loaders\n",
    "5. an optimizer and a scheduler\n",
    "6. an attack object\n",
    "7. a trainer object\n",
    "8. an evaluator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bcai_art.utils_misc import paramdict_to_args, ObjectFromDict, NORM_INF\n",
    "from bcai_art.datasets_main import create_dataset, get_shaped_tensor, \\\n",
    "    DATASET_TYPE, DATASET_NAME_PARAM, DATASET_ROOT_PARAM, \\\n",
    "    DATASET_MEAN_PARAM, DATASET_STD_PARAM, \\\n",
    "    DATASET_NUM_CHANNELS_PARAM, DATASET_NUM_CLASSES_PARAM, \\\n",
    "    DATASET_LOWER_LIMIT_PARAM, DATASET_UPPER_LIMIT_PARAM\n",
    "from bcai_art.train import create_optimizer, create_trainer, compute_lr_steps, create_scheduler, \\\n",
    "    TrainEvalEnviron, train, TRAINER_ADV_PLUG_ATTACK\n",
    "from bcai_art.eval import evaluate, EVALUATOR_NORMAL, EVALUATOR_ATTACK, create_evaluator\n",
    "from bcai_art.models_main import create_toplevel_model, MODEL_ARCH_ATTR\n",
    "from bcai_art.attacks import create_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MNIST dataset\n",
    "We will eperiment with the MNIST dataset, which will be downloadedautomatically to directory `./data`. Some of our datasets need to be downloaded \n",
    "(and optionally processed manually) before they can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'mnist'\n",
    "DATASET_ROOT = './data'  # Where to download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most common random seed after 0!!!\n",
    "# https://twitter.com/jakevdp/status/1247742792861757441\n",
    "RANDOM_SEED=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Toy model\n",
    "We use a small, toy, model that works well on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'mnistnet'\n",
    "USE_PRETRAINED = False  # This MNIST model has no pre-trained version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need to create directories to store logs and model snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPER_DIR = 'sample_exper_dir/train_pgd_mnist_sample'\n",
    "SNAPSHOT_DIR = os.path.join(EXPER_DIR, 'snapshots')\n",
    "LOG_DIR = os.path.join(EXPER_DIR, 'logs')\n",
    "\n",
    "# EXPER_DIR must go first\n",
    "for dn in [EXPER_DIR, SNAPSHOT_DIR, LOG_DIR]:\n",
    "    if os.path.exists(dn):\n",
    "        shutil.rmtree(dn)\n",
    "    os.makedirs(dn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can optionally save logs using Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This example runs only on a single GPU\n",
    "It can run on CPU as well (if you change DEVICE_NAME to 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_NAME = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let us create the dataset object\n",
    "Dataset parameters returned by this function as well. In this example, they are stored in the variable `dataset_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, \\\n",
    "dataset_info = create_dataset(ObjectFromDict({DATASET_NAME_PARAM: DATASET_NAME,\n",
    "                                              DATASET_ROOT_PARAM: DATASET_ROOT}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ObjectFromDict explanation\n",
    "A lot of our API functions receive parameters bundled together in a Python object, where attribute names correspond to parameter names. For convenience, we provide a wrapper object\n",
    "that converts parameter dictionaries to such objects: `ObjectFromDict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let us unpack dataset parameters as we need them for the wrapper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image and video have several input channels\n",
    "channel_qty = dataset_info[DATASET_NUM_CHANNELS_PARAM]\n",
    "# Number of classes\n",
    "class_qty = dataset_info[DATASET_NUM_CLASSES_PARAM]\n",
    "\n",
    "# Mean, STD and upper/lower limit values are used for normalization and clamping\n",
    "norm_mean = get_shaped_tensor(dataset_info, DATASET_MEAN_PARAM)\n",
    "norm_std = get_shaped_tensor(dataset_info, DATASET_STD_PARAM)\n",
    "\n",
    "upper_limit = get_shaped_tensor(dataset_info, DATASET_UPPER_LIMIT_PARAM)\n",
    "lower_limit = get_shaped_tensor(dataset_info, DATASET_LOWER_LIMIT_PARAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we can create a (top-level) wrapper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trainable parameters: 1199882\n"
     ]
    }
   ],
   "source": [
    "# A dictionary with optional model arguments (object attributes)\n",
    "model_args = paramdict_to_args({ MODEL_ARCH_ATTR : MODEL_NAME })\n",
    "\n",
    "model = create_toplevel_model(num_classes=class_qty,\n",
    "                              mean = norm_mean,\n",
    "                              std = norm_std,\n",
    "                              model_arg_obj=model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating an optimizer and a scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=512\n",
    "EPOCH_QTY=10\n",
    "\n",
    "SHUFFLE_TRAIN=True\n",
    "NUM_DATA_WORKERS=2  # number of processes for the data loader\n",
    "\n",
    "\n",
    "OPTIMIZER_ARGS_DICT = {\"momentum\": 0.9, \"weight_decay\": 0.256}\n",
    "OPTIM_TYPE='sgd'\n",
    "# Not used when scheduler is specified\n",
    "INIT_LR=1e-3\n",
    "\n",
    "optim_args = paramdict_to_args(OPTIMIZER_ARGS_DICT)\n",
    "optimizer = create_optimizer(OPTIM_TYPE, model, INIT_LR, optim_args)\n",
    "\n",
    "# scheduler is optional (can be None)\n",
    "SCHEDULER_TYPE = 'one_cycle'\n",
    "SCHEDULER_ARGS = {\n",
    "    \"max_lr\": 0.0002,\n",
    "    \"anneal_strategy\": \"linear\",\n",
    "    \"pct_start\": 0.2\n",
    "}\n",
    "scheduler_args = paramdict_to_args(SCHEDULER_ARGS)\n",
    "\n",
    "\n",
    "lr_steps = compute_lr_steps(epoch_qty=EPOCH_QTY,\n",
    "                            train_set=train_set,\n",
    "                            batch_size=BATCH_SIZE)\n",
    "\n",
    "if lr_steps > 0:\n",
    "    scheduler = create_scheduler(optimizer, SCHEDULER_TYPE, lr_steps, scheduler_args)\n",
    "else:\n",
    "    print('Not creating the scheduler, because the number of steps is not positive!')\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a training environment object\n",
    "`TrainEvalEnviron` is a wrapper class for training and evaluation environment that\n",
    "       encapsulates a model, an optional adversarial perturbation,\n",
    "       and an optimizer. It also provides a few convenience functions to simplify training,\n",
    "       including a multi-device/multi-processing training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = TrainEvalEnviron(DEVICE_NAME,\n",
    "                             train_set,\n",
    "                             dataset_info[DATASET_TYPE],\n",
    "                             BATCH_SIZE,\n",
    "                             device_qty=1, para_type=None,\n",
    "                             model=model,\n",
    "                             train_model=True, # it means that the model will be trained\n",
    "                             adv_perturb=None,\n",
    "                             train_attack=False, # the attack is not trained and there're no initial attack weights\n",
    "                             optimizer=optimizer,\n",
    "                             lower_limit=lower_limit, upper_limit=upper_limit,\n",
    "                             log_writer=writer,\n",
    "                             use_amp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let us create a (PGD) attack object that we use for both training & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating attack: pgd target: None epsilon: 0.2 norm: linf add args: {'alpha': 0.05, 'num_iters': 10, 'restarts': 1, 'start': 'random'}\n"
     ]
    }
   ],
   "source": [
    "ATTACK_TARGET_ID=None  # Can be used for targeted attack\n",
    "# Here's a dictionary describing PGD attack parameters\n",
    "ATTACK_TYPE=\"pgd\"\n",
    "ATTACK_EPS=0.2\n",
    "ATTACK_NORM=NORM_INF\n",
    "\n",
    "ATTACK_ADD_ARGS = {\n",
    "    \"alpha\": 0.05,\n",
    "    \"num_iters\": 10,\n",
    "    \"restarts\": 1,\n",
    "    \"start\": \"random\"\n",
    "}\n",
    "\n",
    "# To create an adversarial trainer we need to create an attack object first\n",
    "add_attack_args = paramdict_to_args(ATTACK_ADD_ARGS)\n",
    "# PGD attack has no weights file, but for the trainable attack\n",
    "# one needs to load weights and specify them in the TrainEvalEnviron constructor\n",
    "trainer_attack_obj = create_attack(ATTACK_TYPE,\n",
    "                                       inner_attack=None,\n",
    "                                       target=ATTACK_TARGET_ID,\n",
    "                                       epsilon=ATTACK_EPS,\n",
    "                                       norm_name=ATTACK_NORM,\n",
    "                                       add_args=add_attack_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can now create a trainer object to train the model adversarially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER_TYPE=TRAINER_ADV_PLUG_ATTACK\n",
    "\n",
    "trainer = create_trainer(TRAINER_TYPE,\n",
    "                         train_env,\n",
    "                         trainer_attack=trainer_attack_obj,\n",
    "                         trainer_args=None) # No additional arguments for this trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, pin_memory=True,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=SHUFFLE_TRAIN,\n",
    "                                           drop_last=True, # drop the last incomplete batch!\n",
    "                                           num_workers=NUM_DATA_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, we have all the necessary ingredients to train the model (adversarially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr: 0.000104 avg. loss: 1.4815 avg acc: 0.4846: 100%|█████████████████████████████████████████████████████| 117/117 [00:12<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t Avg. Loss: 1.4815\t Avg. Accuracy: 0.4846\t Avg. Batch Time: 0.100\n",
      "total train time: 0.2203 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr: 0.000200 avg. loss: 0.6580 avg acc: 0.7898: 100%|█████████████████████████████████████████████████████| 117/117 [00:12<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\t Avg. Loss: 0.6580\t Avg. Accuracy: 0.7898\t Avg. Batch Time: 0.101\n",
      "total train time: 0.4310 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr: 0.000175 avg. loss: 0.4704 avg acc: 0.8531: 100%|█████████████████████████████████████████████████████| 117/117 [00:12<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\t Avg. Loss: 0.4704\t Avg. Accuracy: 0.8531\t Avg. Batch Time: 0.100\n",
      "total train time: 0.6433 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr: 0.000150 avg. loss: 0.3924 avg acc: 0.8782: 100%|█████████████████████████████████████████████████████| 117/117 [00:12<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\t Avg. Loss: 0.3924\t Avg. Accuracy: 0.8782\t Avg. Batch Time: 0.101\n",
      "total train time: 0.8558 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr: 0.000125 avg. loss: 0.3572 avg acc: 0.8915: 100%|█████████████████████████████████████████████████████| 117/117 [00:12<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\t Avg. Loss: 0.3572\t Avg. Accuracy: 0.8915\t Avg. Batch Time: 0.101\n",
      "total train time: 1.0680 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr: 0.000100 avg. loss: 0.3274 avg acc: 0.9010: 100%|█████████████████████████████████████████████████████| 117/117 [00:12<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\t Avg. Loss: 0.3274\t Avg. Accuracy: 0.9010\t Avg. Batch Time: 0.101\n",
      "total train time: 1.2827 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr: 0.000075 avg. loss: 0.3014 avg acc: 0.9085: 100%|█████████████████████████████████████████████████████| 117/117 [00:12<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\t Avg. Loss: 0.3014\t Avg. Accuracy: 0.9085\t Avg. Batch Time: 0.101\n",
      "total train time: 1.4923 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr: 0.000050 avg. loss: 0.2819 avg acc: 0.9148: 100%|█████████████████████████████████████████████████████| 117/117 [00:12<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\t Avg. Loss: 0.2819\t Avg. Accuracy: 0.9148\t Avg. Batch Time: 0.101\n",
      "total train time: 1.7018 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr: 0.000025 avg. loss: 0.2636 avg acc: 0.9188: 100%|█████████████████████████████████████████████████████| 117/117 [00:12<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\t Avg. Loss: 0.2636\t Avg. Accuracy: 0.9188\t Avg. Batch Time: 0.101\n",
      "total train time: 1.9114 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr: -0.000000 avg. loss: 0.2495 avg acc: 0.9248: 100%|████████████████████████████████████████████████████| 117/117 [00:12<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\t Avg. Loss: 0.2495\t Avg. Accuracy: 0.9248\t Avg. Batch Time: 0.101\n",
      "total train time: 2.1216 minutes\n"
     ]
    }
   ],
   "source": [
    "# Run the training procedure\n",
    "train(train_loader,\n",
    "      dataset_info=dataset_info,\n",
    "      trainer=trainer,\n",
    "      num_epochs=EPOCH_QTY,\n",
    "      batch_sync_step=1, # Isn't really used if the number of GPUs == 1\n",
    "      scheduler=scheduler,\n",
    "      snapshot_dir=SNAPSHOT_DIR,\n",
    "      seed=RANDOM_SEED,\n",
    "      is_master_proc=True,\n",
    "      print_train_stat=False) # This is only additional debug stat, mostly useless here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating an evaluation environment object\n",
    "Similar to training, we create the object of the type `TrainEvalEnviron`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally evaluate the model, this requires a separate environment:\n",
    "eval_train_env = TrainEvalEnviron(DEVICE_NAME,\n",
    "                                  test_set,\n",
    "                                  dataset_info[DATASET_TYPE],\n",
    "                                  BATCH_SIZE,\n",
    "                                  device_qty=1, para_type=None,\n",
    "                                  model=model, train_model=False, # no model training\n",
    "                                  adv_perturb=None, train_attack=False, # no attack training\n",
    "                                  optimizer=None,\n",
    "                                  lower_limit=lower_limit, upper_limit=upper_limit,\n",
    "                                  log_writer=writer, use_amp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let us create a test loader and to evaluate the model\n",
    "The model is going to be tested under normal circumstances as well as under the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, pin_memory=True,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=False,\n",
    "                                           drop_last=False,\n",
    "                                           num_workers=NUM_DATA_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation on clean, i.e., unmodified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg. loss: 0.0277 avg acc: 0.9912: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average batch time: 0.005\n",
      "loss 0.0277\n",
      "accuracy 0.9912\n",
      "{\n",
      "    \"batch_time\": 0.004989314079284668,\n",
      "    \"loss\": 0.027656947374343873,\n",
      "    \"accuracy\": 0.9912\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "EVAL_ADD_ARGS_NORMAL = {}\n",
    "eval_add_args_normal = paramdict_to_args(EVAL_ADD_ARGS_NORMAL)\n",
    "\n",
    "# We run two evaluations here: normal & PGD adversary attack\n",
    "evaluator_obj_normal = create_evaluator(EVALUATOR_NORMAL, \n",
    "                                        eval_train_env, \n",
    "                                        eval_add_args_normal, \n",
    "                                        eval_attack_obj=None)\n",
    "\n",
    "stat = evaluate(test_loader, 'normal evaluator', evaluator_obj_normal)\n",
    "print(json.dumps(stat, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation of the model under attack\n",
    "Note that we use the type of the attack as we used for training, but we can surely use a different type of attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample_qty': 20}\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_QTY=20 # Number of perturbed images to save\n",
    "\n",
    "EVAL_ADD_ARGS_ATTACK = {'sample_qty' : SAMPLE_QTY}\n",
    "eval_add_args_attack = paramdict_to_args(EVAL_ADD_ARGS_ATTACK)\n",
    "eval_attack_obj = trainer_attack_obj # We are reusing the same attack object, but we can create a different one too\n",
    "evaluator_obj_pgd = create_evaluator(EVALUATOR_ATTACK, \n",
    "                                     eval_train_env, \n",
    "                                     eval_add_args_attack, \n",
    "                                     eval_attack_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As we can see, the model performs worse under attack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg. loss: 0.1423 avg acc: 0.9558: 100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average batch time: 0.095\n",
      "loss 0.1423\n",
      "accuracy 0.9558\n",
      "attack_success 0.0360\n",
      "{\n",
      "    \"batch_time\": 0.09535449743270874,\n",
      "    \"loss\": 0.14231307804584503,\n",
      "    \"accuracy\": 0.9558,\n",
      "    \"attack_success\": 0.036\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "stat = evaluate(test_loader, 'PGD evaluator', evaluator_obj_pgd)\n",
    "print(json.dumps(stat, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the end, we need to close the Tensorboard log writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
